rule extract_salmon_num_reads:
    input:
        "results/salmon/{sample}/quant.sf"
    output:
        "results/salmon_reads/{sample}/{sample}.salmon_num_reads.txt"
    conda:
        "../envs/python3.yaml"
    log:
        "logs/{sample}/extract_salmon_NumReads/{sample}.extract_salmon_NumReads.log",
    params:
        script = "workflow/scripts/python/extract_salmon_NumReads.py",
        sample_id=lambda wildcards: wildcards.sample,
    threads:
        48
    shell:
        "python3.8 {params.script} {input} {output} {params.sample_id} -t {threads} &>{log}"

rule merge_salmon_NumReads:
    input:
        expand("results/salmon_reads/{sample}/{sample}.salmon_num_reads.txt", sample=SAMPLES)
    output:
        "results/salmon_combined/salmon_num_reads_merged_file.csv"
    conda:
        "../envs/python3.yaml"
    run:
        import pandas as pd
        
        # Load the first file as the base DataFrame
        base_df = pd.read_csv(input[0], delimiter='\t')
        print(f"Columns in {input[0]}: {base_df.columns.tolist()}")

        # Iterate over the remaining files and left join them based on "Name"
        for file in input[1:]:
            df = pd.read_csv(file, delimiter='\t')
            print(f"Columns in {file}: {df.columns.tolist()}")
            base_df = base_df.merge(df, on="Name", how="left")
        
        # Rename the column "Name" to "contig_id"
        base_df = base_df.rename(columns={"Name": "contig_id"})

        # Save the final joined DataFrame to the output file
        base_df.to_csv(output[0], index=False)

rule normalize_salmon_counts:
    input:
        "results/salmon_combined/salmon_num_reads_merged_file.csv"
    output:
        "results/salmon_combined/salmon_num_reads_normalized.csv"
    conda:
        "../envs/python3.yaml"
    run:
        import pandas as pd
        import numpy as np

        # Load the merged file
        df = pd.read_csv(input[0])

        # Add the lengths of contigs to the df
        df['Length'] = df['contig_id'].str.extract(r'length_(\d+)_cov').astype(int)
        print('Lengths type is', df['Length'].dtype)
        print('Lengths added to the DataFrame')

        # Convert the lengths to effective lengths
        df['EffectiveLength'] = np.log10(df['Length'])
        print('EffectiveLengths added to the DataFrame')

        # Normalize the counts by the effective lengths, excluding the "contig_id" column, and keep two decimal places
        df_normalized = df.iloc[:, 1:].div(df['EffectiveLength'], axis=0).round(2)
        print('Data normalized by EffectiveLength')

        # Remove the "Length" and "EffectiveLength" columns
        df_normalized = df_normalized.drop(columns=['Length', 'EffectiveLength'])
        print('Length and EffectiveLength columns removed')
        
        # Add the "contig_id" column back to the DataFrame
        df_normalized.insert(0, 'contig_id', df['contig_id'])

        # Save the normalized counts to the output file
        df_normalized.to_csv(output[0], index=False)
        print('Normalized counts saved to the output file')
